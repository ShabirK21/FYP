{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e71bf-248a-45e0-96d6-54a1354e8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.image as tfi\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Add\n",
    "from keras.layers import Multiply\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5cf96-0cba-4aa2-b949-fa52dd737d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "ROOT_DIR = 'datasets/Dataset_BUSI_with_GT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356246c-5d5b-4e64-a097-83782d36fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image, SIZE):\n",
    "    return np.round(tfi.resize(img_to_array(load_img(image)) / 255., (SIZE, SIZE)), 4)\n",
    "\n",
    "def load_images(image_paths, SIZE, mask=False, trim=None):\n",
    "    if trim is not None:\n",
    "        image_paths = image_paths[:trim]\n",
    "    \n",
    "    images = np.array([load_image(image, SIZE) for image in image_paths])\n",
    "    \n",
    "    if mask:\n",
    "        images = images[:, :, :, :1]\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f72b9f-47cb-40a8-bed2-770d66daf0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=None, cmap=None, alpha=1):\n",
    "    plt.imshow(image, cmap=cmap, alpha=alpha)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def show_mask(image, mask, cmap=None, alpha=0.4):\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820b98b-c689-4ea3-8dc3-4f7bba52cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(os.listdir(ROOT_DIR))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38236f-4508-4de3-b2ca-82459c745993",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mask_paths = sorted([sorted(glob(ROOT_DIR + name + \"/*mask.png\")) for name in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7782f44-bff1-4145-8761-7b6406abae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "mask_paths = []\n",
    "for class_path in single_mask_paths:\n",
    "    for path in class_path:\n",
    "        img_path = path.replace('_mask','')\n",
    "        image_paths.append(img_path)\n",
    "        mask_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd31d7-d203-437a-9f42-1e106d5e45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(load_image(image_paths[0], SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672b4d8-3352-4355-b380-a709a4282958",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mask(load_image(image_paths[0], SIZE), load_image(mask_paths[0], SIZE)[:,:,0], alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4f056-dd6d-404e-a3b9-3f5096d41846",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(image_paths, SIZE)\n",
    "masks = load_images(mask_paths, SIZE, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b2c11-2b97-4085-840b-e8ecc1e85b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    id = np.random.randint(len(images))\n",
    "    show_mask(images[id], masks[id], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16736ae5-3d81-49da-9103-8059887c81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(Layer):\n",
    "\n",
    "    def __init__(self, filters, rate, pooling=True, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.rate = rate\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "        self.drop = Dropout(rate)\n",
    "        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "        self.pool = MaxPool2D()\n",
    "\n",
    "    def call(self, X):\n",
    "        x = self.c1(X)\n",
    "        x = self.drop(x)\n",
    "        x = self.c2(x)\n",
    "        if self.pooling:\n",
    "            y = self.pool(x)\n",
    "            return y, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"filters\":self.filters,\n",
    "            'rate':self.rate,\n",
    "            'pooling':self.pooling\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183bb1f-0d6d-4746-8eaf-d213fd566f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(Layer):\n",
    "\n",
    "    def __init__(self, filters, rate, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.rate = rate\n",
    "\n",
    "        self.up = UpSampling2D()\n",
    "        self.net = EncoderBlock(filters, rate, pooling=False)\n",
    "\n",
    "    def call(self, X):\n",
    "        X, skip_X = X\n",
    "        x = self.up(X)\n",
    "        c_ = concatenate([x, skip_X])\n",
    "        x = self.net(c_)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"filters\":self.filters,\n",
    "            'rate':self.rate,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce2e15-124e-4968-8691-f6863ae62458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGate(Layer):\n",
    "\n",
    "    def __init__(self, filters, bn, **kwargs):\n",
    "        super(AttentionGate, self).__init__(**kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.bn = bn\n",
    "\n",
    "        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')\n",
    "        self.resample = UpSampling2D()\n",
    "        self.BN = BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        X, skip_X = X\n",
    "\n",
    "        x = self.normal(X)\n",
    "        skip = self.down(skip_X)\n",
    "        x = Add()([x, skip])\n",
    "        x = self.learn(x)\n",
    "        x = self.resample(x)\n",
    "        f = Multiply()([x, skip_X])\n",
    "        if self.bn:\n",
    "            return self.BN(f)\n",
    "        else:\n",
    "            return f\n",
    "        # return f\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"filters\":self.filters,\n",
    "            \"bn\":self.bn\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e7486-136e-4ca8-ad7b-164316aa036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowProgress(Callback):\n",
    "    def on_epoch_end(self, epochs, logs=None):\n",
    "        id = np.random.randint(200)\n",
    "        exp = GradCAM()\n",
    "        image = images[id]\n",
    "        mask = masks[id]\n",
    "        pred_mask = self.model.predict(image[np.newaxis,...])\n",
    "        cam = exp.explain(\n",
    "            validation_data=(image[np.newaxis,...], mask),\n",
    "            class_index=1,\n",
    "            layer_name='Attention4',\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(\"Original Mask\")\n",
    "        show_mask(image, mask, cmap='copper')\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        show_mask(image, pred_mask, cmap='copper')\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        show_image(cam,title=\"GradCAM\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfb140-f57e-4b9b-af9b-b96744b61614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_layer = Input(shape=images.shape[-3:])\n",
    "\n",
    "# Encoder\n",
    "p1, c1 = EncoderBlock(32,0.1, name=\"Encoder1\")(input_layer)\n",
    "p2, c2 = EncoderBlock(64,0.1, name=\"Encoder2\")(p1)\n",
    "p3, c3 = EncoderBlock(128,0.2, name=\"Encoder3\")(p2)\n",
    "p4, c4 = EncoderBlock(256,0.2, name=\"Encoder4\")(p3)\n",
    "\n",
    "# Encoding\n",
    "encoding = EncoderBlock(512,0.3, pooling=False, name=\"Encoding\")(p4)\n",
    "\n",
    "# Attention + Decoder\n",
    "\n",
    "a1 = AttentionGate(256, bn=True, name=\"Attention1\")([encoding, c4])\n",
    "d1 = DecoderBlock(256,0.2, name=\"Decoder1\")([encoding, a1])\n",
    "\n",
    "a2 = AttentionGate(128, bn=True, name=\"Attention2\")([d1, c3])\n",
    "d2 = DecoderBlock(128,0.2, name=\"Decoder2\")([d1, a2])\n",
    "\n",
    "a3 = AttentionGate(64, bn=True, name=\"Attention3\")([d2, c2])\n",
    "d3 = DecoderBlock(64,0.1, name=\"Decoder3\")([d2, a3])\n",
    "\n",
    "\n",
    "a4 = AttentionGate(32, bn=True, name=\"Attention4\")([d3, c1])\n",
    "d4 = DecoderBlock(32,0.1, name=\"Decoder4\")([d3, a4])\n",
    "\n",
    "# Output \n",
    "output_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)\n",
    "\n",
    "# Model\n",
    "model = Model(\n",
    "    inputs=[input_layer],\n",
    "    outputs=[output_layer]\n",
    ")\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', MeanIoU(num_classes=2, name='IoU')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00268fee-f2e3-444b-9acd-18322032e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Training\n",
    "BATCH_SIZE = 8\n",
    "SPE = len(images)//BATCH_SIZE\n",
    "\n",
    "# Training\n",
    "results = model.fit(\n",
    "    images, masks,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=SPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18078c-815d-48ce-8221-7cd099d5d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25))\n",
    "n=0\n",
    "for i in range(1,(5*3)+1):\n",
    "    plt.subplot(5,3,i)\n",
    "    if n==0:\n",
    "        id = np.random.randint(len(images))\n",
    "        image = images[id]\n",
    "        mask = masks[id]\n",
    "        pred_mask = model.predict(image[np.newaxis,...])\n",
    "\n",
    "        plt.title(\"Original Mask\")\n",
    "        show_mask(image, mask)\n",
    "        n+=1\n",
    "    elif n==1:\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        show_mask(image, pred_mask)\n",
    "        n+=1\n",
    "    elif n==2:\n",
    "        pred_mask = (pred_mask>0.5).astype('float')\n",
    "        plt.title(\"Processed Mask\")\n",
    "        show_mask(image, pred_mask)\n",
    "        n=0\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
